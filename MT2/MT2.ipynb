{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1f6024a2",
      "metadata": {
        "id": "1f6024a2"
      },
      "source": [
        "# Mid-Term\n",
        "\n",
        "In this second mid-term assignment we focus on Kernel Regularized Least Squares (KRLS).\n",
        "You are given different synthetic datasets (only training and validation!) to be used with KRLS. To ease your life, we provide the code for KRLS training and inference.\n",
        "\n",
        "What you need to do:\n",
        "- Set up a pipeline for training KRLS for different choices of the kernel function. This should also include an appropriate model selection (meaning that you need to appropriately select the value of the hyperparameter and, if needed, the parameters of the kernel function)\n",
        "- Select among the different solutions the one that you think is the best for the provided datasets. We will evaluate your model on the test sets. To facilitate this step, please provide the code for\n",
        "    - Final training, meaning the training with the hyperparameters and kernel parameters that you selected for each dataset\n",
        "    - Test of the trained model on the test set (this last step can not be run by you, as you don't have the test)\n",
        "    \n",
        "PLEASE, COMMENT YOUR CODE!\n",
        "\n",
        "We provide here two functions to load data, compute the MSE, train and test KRLS.\n",
        "Moreover, here are some details about the datasets:\n",
        "- dataset 1: 700 points (500 for training and 200 for validation) in 5 dimensions\n",
        "- dataset 2: 4500 points (4000 for training and 500 for validation) in 5 dimensions\n",
        "- dataset 3: 150 points (100 for training and 50 for validation) in 5 dimensions\n",
        "- dataset 4: 2500 points (2000 for training and 500 for validation) in 10 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d131775e",
      "metadata": {
        "id": "d131775e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "552a89a7",
      "metadata": {
        "id": "552a89a7"
      },
      "source": [
        "We provide here two functions to load data and compute the MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75012523",
      "metadata": {
        "id": "75012523"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"./datasets/\"\n",
        "\n",
        "def load_dataset(name, d):\n",
        "    # name: file path\n",
        "    # d : dimension of input space\n",
        "    X, y = [], []\n",
        "    with open(\"{}\".format(name), 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            splitted = line.split(\",\")\n",
        "            X.append(splitted[:-1])\n",
        "            y.append(splitted[-1])\n",
        "    X, y = np.asarray(X, dtype=np.float64).reshape(-1, d), np.asarray(y, dtype=np.float64).reshape(-1, 1)\n",
        "    return X, y\n",
        "\n",
        "def calc_err(Ypred, Ytrue):\n",
        "    return np.mean((Ypred-Ytrue)**2)\n",
        "\n",
        "def squared_distances(X1, X2):\n",
        "    \"\"\"Compute the matrix of pairwise squared-distances between all points in X1 and in X2.\n",
        "    \"\"\"\n",
        "    return scipy.spatial.distance.cdist(X1, X2, metric='seuclidean')\n",
        "\n",
        "def kernel_matrix(X1, X2, kernel_type, param):\n",
        "    # X1 : array of shape n x d\n",
        "    # X2 : array of shape m x d\n",
        "    if kernel_type == 'linear':\n",
        "        return X1 @ X2.T\n",
        "    elif kernel_type == 'polynomial':\n",
        "        exponent = param\n",
        "        return (X1 @ X2.T + 1)**exponent\n",
        "    elif kernel_type == 'gaussian':\n",
        "        lengthscale = param\n",
        "        return np.exp((-squared_distances(X1,X2)) / (2 * (lengthscale**2)))\n",
        "    else:\n",
        "        raise ValueError(kernel_type)\n",
        "\n",
        "def krls_train(x, y, reg_par, kernel_type, kernel_par):\n",
        "    n,D = x.shape\n",
        "    w = np.linalg.solve((kernel_matrix(x, x, kernel_type, kernel_par) + (n * reg_par * np.identity(n))), y)\n",
        "    return w\n",
        "\n",
        "def krls_predict(x_ts, x_tr, w, kernel_type, kernel_par):\n",
        "    return kernel_matrix(x_ts, x_tr, kernel_type, kernel_par) @ w\n",
        "\n",
        "# KFoldCV\n",
        "\n",
        "def krls_kfold_valerr(x_tr, y_tr, num_folds, reg_par, kernel_type, kernel_par):\n",
        "    \"\"\"\n",
        "    Compute the k-fold cross-validation error for one KRLS model (with speficied regularization,\n",
        "    kernel and kernel parameter).\n",
        "\n",
        "    This function returns both the training errors and the validation errors\n",
        "    obtained from CV (as numpy arrays).\n",
        "    \"\"\"\n",
        "    if num_folds <= 1:\n",
        "        raise Exception(\"Please supply a number of folds > 1\")\n",
        "\n",
        "    n_tot = x_tr.shape[0]\n",
        "    n_val = int(n_tot // num_folds)\n",
        "\n",
        "    tr_errs, val_errs = [], []\n",
        "    # `split_idx`: a list of arrays, each containing the validation indices for 1 fold\n",
        "    rand_idx = np.random.choice(n_tot, size=n_tot, replace=False)\n",
        "    split_idx = np.array_split(rand_idx, num_folds)\n",
        "    for fold in range(num_folds):\n",
        "        # Set the indices in boolean mask for all validation samples to `True`\n",
        "        val_mask = np.zeros(n_tot, dtype=bool)\n",
        "        val_mask[split_idx[fold]] = True\n",
        "\n",
        "        kf_x_tr = x_tr[~val_mask]\n",
        "        kf_y_tr = y_tr[~val_mask]\n",
        "        kf_x_val = x_tr[val_mask]\n",
        "        kf_y_val = y_tr[val_mask]\n",
        "\n",
        "        w_krls = krls_train(kf_x_tr, kf_y_tr, reg_par=reg_par,\n",
        "                            kernel_type=kernel_type, kernel_par=kernel_par)\n",
        "\n",
        "        pred_tr = krls_predict(kf_x_tr, kf_x_tr, w_krls,\n",
        "                               kernel_type=kernel_type, kernel_par=kernel_par)\n",
        "        pred_val = krls_predict(kf_x_val, kf_x_tr, w_krls,\n",
        "                                kernel_type=kernel_type, kernel_par=kernel_par)\n",
        "        tr_errs.append(calc_err(pred_tr, kf_y_tr))\n",
        "        val_errs.append(calc_err(pred_val, kf_y_val))\n",
        "    return np.asarray(tr_errs), np.asarray(val_errs)\n",
        "\n",
        "def krls_kfoldcv(x_tr, y_tr, num_folds, reg_par_list, kernel_type, kernel_par_list):\n",
        "    \"\"\"Choose the best parameters for both the regularizer and the kernel parameter according to K-Fold CV.\n",
        "    \"\"\"\n",
        "    errors = np.zeros((len(reg_par_list), len(kernel_par_list)))\n",
        "    for i, reg_par in enumerate(reg_par_list):\n",
        "        for j, kernel_par in enumerate(kernel_par_list):\n",
        "            tr_error, val_error = krls_kfold_valerr(\n",
        "                x_tr, y_tr, num_folds, reg_par, kernel_type, kernel_par)\n",
        "            errors[i][j] = np.mean(val_error)\n",
        "\n",
        "    best_reg_par = reg_par_list[np.unravel_index(\n",
        "        np.argmin(errors), errors.shape)[0]]\n",
        "    best_kernel_par = kernel_par_list[np.unravel_index(\n",
        "        np.argmin(errors), errors.shape)[1]]\n",
        "    best_err = np.min(errors)\n",
        "    print(f\"The best error (MSE={best_err:.2f}) was obtained with \"\n",
        "          f\"lambda={best_reg_par:.1g}, kernel-parameter={best_kernel_par}\")\n",
        "    return best_reg_par, best_kernel_par, best_err"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "phAEDjGhW8p7",
      "metadata": {
        "id": "phAEDjGhW8p7"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lhjxqbojW-_K",
      "metadata": {
        "id": "lhjxqbojW-_K"
      },
      "outputs": [],
      "source": [
        "(Xtr_1, ytr_1), (Xte_1, yte_1) = load_dataset(DATASET_PATH + \"dataset_1_train\", d=5), load_dataset(DATASET_PATH + \"dataset_1_val\", d=5)\n",
        "(Xtr_2, ytr_2), (Xte_2, yte_2) = load_dataset(DATASET_PATH + \"dataset_2_train\", d=5), load_dataset(DATASET_PATH + \"dataset_2_val\", d=5)\n",
        "(Xtr_3, ytr_3), (Xte_3, yte_3) = load_dataset(DATASET_PATH + \"dataset_3_train\", d=5), load_dataset(DATASET_PATH + \"dataset_3_val\", d=5)\n",
        "(Xtr_4, ytr_4), (Xte_4, yte_4) = load_dataset(DATASET_PATH + \"dataset_4_train\", d=10), load_dataset(DATASET_PATH + \"dataset_4_val\", d=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zwnHgodYW2SK",
      "metadata": {
        "id": "zwnHgodYW2SK"
      },
      "source": [
        "# Training KRLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sQi3M_s_W02_",
      "metadata": {
        "id": "sQi3M_s_W02_"
      },
      "outputs": [],
      "source": [
        "KF = 5\n",
        "lam_list = np.logspace(-9, 2, 10)\n",
        "kernel_par_list = np.arange(1, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EXto8BXSPiat",
      "metadata": {
        "id": "EXto8BXSPiat"
      },
      "outputs": [],
      "source": [
        "# find the hyperparameter with KFoldCV\n",
        "# Train KRLS model for different kernels\n",
        "def model_selection(Xtr, ytr, Xte, yte):\n",
        "  err = []\n",
        "\n",
        "  for k_type in [\"linear\", \"polynomial\", \"gaussian\"]:\n",
        "    best_lam, best_kernel_par, best_err = krls_kfoldcv(Xtr, ytr, KF, lam_list, k_type, kernel_par_list)\n",
        "    err.append((best_lam, best_kernel_par, best_err, k_type))\n",
        "\n",
        "\n",
        "    # Plot training and validation error\n",
        "    _, ax = plt.subplots()\n",
        "    ax.plot(lam_list, val_error, '-o', label=\"Validation error\")\n",
        "    ax.plot(lam_list, tr_error, '-o', label=\"Train error\")\n",
        "    ax.axvline(best_lam, linestyle=\"--\", c=\"red\", alpha=0.7, label=\"best $\\lambda$\")\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xlabel(\"$\\lambda$\")\n",
        "    ax.set_ylabel(\"MSE\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    ax.set_title(f\"Type of kernel is: {k_type}\")\n",
        "\n",
        "  best_lam, best_kernel_par, best_err, best_k_type = min(err, key=lambda tup: tup[2])\n",
        "  w = krls_train(Xtr, ytr, best_lam, best_k_type, best_kernel_par)\n",
        "  y_pred = krls_predict(Xte, Xtr, w, best_k_type, best_kernel_par)\n",
        "\n",
        "  print(f\"Best Kernel type: {best_k_type}\")\n",
        "  print(f\"Best Kernel parameter: {best_kernel_par}\")\n",
        "  print(f\"Best Regularization parameter: {best_lam}\")\n",
        "  print(f\"Best Error parameter: {best_err}\")\n",
        "\n",
        "\n",
        "  return w, y_pred # DA RIVEDERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, y_pred=model_selection(Xtr_1, ytr_1, Xte_1, yte_1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.title(\"Dataset 1\")\n",
        "ax.scatter(Xte_1[:,0], yte_1, label=\"True\" )\n",
        "ax.scatter(Xte_1[:200,0], y_pred, label=\"Predict\" )\n",
        "ax.legend(loc=\"best\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XkYt0dCyM0yU"
      },
      "id": "XkYt0dCyM0yU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, y_pred=model_selection(Xtr_2, ytr_2, Xte_2, yte_2)\n",
        "fig, ax = plt.subplots()\n",
        "plt.title(\"Dataset 2\")\n",
        "ax.scatter(Xte_2[:,0], yte_2, label=\"True\" )\n",
        "ax.scatter(Xte_2[:500,0], y_pred, label=\"Predict\" )\n",
        "ax.legend(loc=\"best\")\n"
      ],
      "metadata": {
        "id": "3Zyj5KXLM3p5"
      },
      "id": "3Zyj5KXLM3p5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w, y_pred=model_selection(Xtr_3, ytr_3, Xte_3, yte_3)\n",
        "fig, ax = plt.subplots()\n",
        "plt.title(\"Dataset 3\")\n",
        "ax.scatter(Xte_3[:,0], yte_3, label=\"True\" )\n",
        "ax.scatter(Xte_3[:50,0], y_pred, label=\"Predict\" )\n",
        "ax.legend(loc=\"best\")\n"
      ],
      "metadata": {
        "id": "z46CnFC6M689"
      },
      "id": "z46CnFC6M689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w, y_pred=model_selection(Xtr_4, ytr_4, Xte_4, yte_4)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.title(\"Dataset 4\")\n",
        "ax.scatter(Xte_4[:,0], yte_4, label=\"True\" )\n",
        "ax.scatter(Xte_4[:500,0], y_pred, label=\"Predict\" )\n",
        "ax.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "Sz14LeSUM7z5"
      },
      "id": "Sz14LeSUM7z5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}